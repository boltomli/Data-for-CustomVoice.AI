{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the audio data may come without text. Feel free to use any library or your own module to do speech recognition (ASR). In this notebook I'll rely on [ffmpeg](https://ffmpeg.org) to extract audio and [cmusphinx](https://cmusphinx.github.io) to recognize speech to text. Check the official websites to find out how to install and configure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpy import FFmpeg\n",
    "\n",
    "def extract_audio(mediafile):\n",
    "    '''Extract audio from supported file and save in mono PCM wave format'''\n",
    "    ff = FFmpeg(inputs={mediafile: None}, outputs={mediafile + '.wav': '-ac 1'})\n",
    "    ff.run()\n",
    "    wavefile = mediafile + '.wav'\n",
    "    return wavefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def speech_recognition(wavefile, lang):\n",
    "    '''Recognize speech to text from wave file with given language'''\n",
    "    reco = sr.Recognizer()\n",
    "    with sr.AudioFile(wavefile) as source:\n",
    "        audio = reco.record(source)\n",
    "    return reco.recognize_sphinx(audio, language=lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends on the ASR library whether a long wave can be split to small pieces. The split step can also be done prior to ASR, for example, with tools like [auditok](https://auditok.readthedocs.io/en/latest/).\n",
    "\n",
    "```\n",
    "auditok -e 55 -i input.wav -m 10 --printf \"{id}\\n{start} --> {end}\\nFake text here...\\n\" --time-format \"%h:%m:%s,%i\" > output.srt\n",
    "```\n",
    "\n",
    "The audio file can be split into segments with the time information provided then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt\n",
    "from ffmpy import FFmpeg\n",
    "\n",
    "for sub in srt.parse(open('output.srt').read()):\n",
    "    ss = sub.start\n",
    "    t = sub.end - ss\n",
    "    ff = FFmpeg(\n",
    "        inputs={'input.wav': ' '.join(['-ss', str(ss), '-t', str(t)])},\n",
    "        outputs={'split/'+str(ss)+'-'+str(t)+'.wav': ' '.join(['-vn', '-acodec', 'pcm_s16le'])}\n",
    "    )\n",
    "    ff.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}